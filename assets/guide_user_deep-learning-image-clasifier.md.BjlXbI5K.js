import{_ as e,c as i,a0 as s,o as t}from"./chunks/framework.BGabeMLJ.js";const u=JSON.parse('{"title":"Applying platform SDK and CLI to run a Deep Learning application","description":"","frontmatter":{},"headers":[],"relativePath":"guide/user/deep-learning-image-clasifier.md","filePath":"guide/user/deep-learning-image-clasifier.md"}'),n={name:"guide/user/deep-learning-image-clasifier.md"};function l(r,a,o,h,p,d){return t(),i("div",null,a[0]||(a[0]=[s(`<h1 id="applying-platform-sdk-and-cli-to-run-a-deep-learning-application" tabindex="-1">Applying platform SDK and CLI to run a Deep Learning application <a class="header-anchor" href="#applying-platform-sdk-and-cli-to-run-a-deep-learning-application" aria-label="Permalink to &quot;Applying platform SDK and CLI to run a Deep Learning application&quot;">​</a></h1><p>The more detailed guide to the deep learning showcase can be read <a href="./Guide-showcase-deep-learning-image-classifier.pdf">here</a></p><div class="warning custom-block"><p class="custom-block-title">Assumed Knowledge</p><p>This guide assumes you&#39;re already familiar with the basic concepts of federated learning. If not, read the background docs on <a href="/guide/user/analysis-coding.html">Coding an Analysis</a> and the <a href="/guide/user/sdk-core-doc.html">Core SDK</a>.</p><div class="info custom-block"><p class="custom-block-title">Summary</p><p>This tutorial shows how to train a deep learning based image classifier on <strong>FLAME</strong> using the external frameworks such as <strong>PyTorch</strong> and the provided reference script <a href="https://github.com/PrivateAIM/showcases/tree/main/image-classifier/Image_analysis_on_flame_cuda.py" download>Image_classifier_training.py</a>. It is a demonstration workflow whose main purpose is to demonstrate platform capabilities for machine learning applications.</p></div></div><div class="info custom-block"><p class="custom-block-title">Download</p><p>Download the full reference script: <a href="https://github.com/PrivateAIM/showcases/tree/main/image-classifier/Image_analysis_on_flame_cuda.py" download>Image_classifier_training.py</a></p></div><h2 id="goal" tabindex="-1">Goal <a class="header-anchor" href="#goal" aria-label="Permalink to &quot;Goal&quot;">​</a></h2><p>Briefly train the neural network based image classifier for a few epochs inside the multi-round federated analysis: handle model weight exchange and aggregation, enforce convergence criteria based on the change in loss function, and compute basic metrics across nodes without moving raw image datasets between nodes.</p><p>By the end of this tutorial you will learn how to use Star patterns, and how to collect the results of federated training.</p><div class="tip custom-block"><p class="custom-block-title">The reason why we use Python as the language of choice is that there is no better alternative for this kind of application due to its suitable ecosystem</p><h2 id="what-does-the-analysis-code" tabindex="-1">What does the analysis code? <a class="header-anchor" href="#what-does-the-analysis-code" aria-label="Permalink to &quot;What does the analysis code?&quot;">​</a></h2><p>Brief overview:</p><ul><li>Analyzer runs network training for few specified number of epochs, then returns a dictionary with updated weights, loss value</li><li>The aggregator subclass computes federated average of the returned model weights, loss and its metrics received from analyzer node, and checks convergence criterion each round</li><li>Upon the training is finished the results are serialized and saved as the pickle file in the Hub storage</li></ul><h2 id="prerequisites" tabindex="-1">Prerequisites <a class="header-anchor" href="#prerequisites" aria-label="Permalink to &quot;Prerequisites&quot;">​</a></h2><ul><li>Properly prepared S3 buckets on MinIO Object Store that include the tarball archive of the used dataset</li><li>Configured datastores on each participating node that refer to respective S3 buckets</li><li>A deep learning master image with all necessary dependencies being available</li></ul><h2 id="output-structure" tabindex="-1">Output Structure <a class="header-anchor" href="#output-structure" aria-label="Permalink to &quot;Output Structure&quot;">​</a></h2><p>An expected real output is a serialized dictionary that includes the following keys with values of data types as shown in the mapping below:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">{</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;model&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:torch.Tensor,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;loss&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;num_classes&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;prediction_scores&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:List[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;accuracy&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;avg_f1&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;avg_precision&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;avg_recall&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">float</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><h2 id="common-issues" tabindex="-1">Common issues <a class="header-anchor" href="#common-issues" aria-label="Permalink to &quot;Common issues&quot;">​</a></h2><h2 id="additional-references" tabindex="-1">Additional references <a class="header-anchor" href="#additional-references" aria-label="Permalink to &quot;Additional references&quot;">​</a></h2><ul><li><a href="/guide/user/analysis-coding.html">The Intro into coding an analysis script</a></li><li><a href="/guide/user/sdk-core-doc.html">The documentation about Core SDK</a></li><li><a href="https://docs.pytorch.org/docs/stable/index.html" target="_blank" rel="noreferrer">PyTorch documentation</a></li></ul><hr><p>Author: Gherman Sergey</p></div>`,8)]))}const g=e(n,[["render",l]]);export{u as __pageData,g as default};
