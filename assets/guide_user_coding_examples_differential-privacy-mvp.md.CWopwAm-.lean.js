import{_ as a,c as s,a0 as e,o as n}from"./chunks/framework.BGabeMLJ.js";const c=JSON.parse('{"title":"Analysis Coding with Local Differential Privacy","description":"","frontmatter":{},"headers":[],"relativePath":"guide/user/coding_examples/differential-privacy-mvp.md","filePath":"guide/user/coding_examples/differential-privacy-mvp.md"}'),t={name:"guide/user/coding_examples/differential-privacy-mvp.md"};function l(r,i,p,h,o,d){return n(),s("div",null,i[0]||(i[0]=[e(`<h1 id="analysis-coding-with-local-differential-privacy" tabindex="-1">Analysis Coding with Local Differential Privacy <a class="header-anchor" href="#analysis-coding-with-local-differential-privacy" aria-label="Permalink to &quot;Analysis Coding with Local Differential Privacy&quot;">​</a></h1><div class="warning custom-block"><p class="custom-block-title">Info</p><p>This section demonstrates the use of Local Differential Privacy in distributed analysis. The example is designed to show how to enhance privacy protection while performing federated analysis across multiple nodes.</p></div><h3 id="example-analysis-using-starlocaldpmodel-counting-patients-with-differential-privacy" tabindex="-1">Example Analysis using <code>StarLocalDPModel</code>: Counting Patients with Differential Privacy <a class="header-anchor" href="#example-analysis-using-starlocaldpmodel-counting-patients-with-differential-privacy" aria-label="Permalink to &quot;Example Analysis using \`StarLocalDPModel\`: Counting Patients with Differential Privacy&quot;">​</a></h3><p>This analysis example demonstrates how to count the total number of patients across multiple nodes with FHIR data, with differential privacy protections applied to the aggregated results. The patient counts from each node are summed and then noise is added to preserve privacy.</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> flame.star </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> StarLocalDPModel, StarAnalyzer, StarAggregator</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># MyAnalyzer and MyAggregator classes remain unchanged from the introduction example</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> main</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    Sets up and initiates the distributed analysis using the FLAME components.</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    - Defines the custom analyzer and aggregator classes.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    - Specifies the type of data and queries to execute.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    - Configures analysis parameters like iteration behavior and output format.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    - Applies differential privacy to protect the aggregated results.</span></span>
<span class="line"><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">    &quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    StarLocalDPModel(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        analyzer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MyAnalyzer,             </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Custom analyzer class (must inherit from StarAnalyzer)</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        aggregator</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MyAggregator,         </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Custom aggregator class (must inherit from StarAggregator)</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        data_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;fhir&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,                </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Type of data source (&#39;fhir&#39; or &#39;s3&#39;)</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        query</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Patient?_summary=count&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Query or list of queries to retrieve data</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        simple_analysis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,            </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># True for single-iteration; False for multi-iterative analysis</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        output_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;str&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,               </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Output format for the final result (&#39;str&#39;, &#39;bytes&#39;, or &#39;pickle&#39;)</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        epsilon</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,                     </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Privacy budget for differential privacy</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        sensitivity</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,                 </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Sensitivity parameter for differential privacy</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        analyzer_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,            </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Additional keyword arguments for the custom analyzer constructor (i.e. MyAnalyzer)</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        aggregator_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">           # Additional keyword arguments for the custom aggregator constructor (i.e. MyAggregator)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    )</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">if</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> __name__</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> ==</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &quot;__main__&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">:</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    main()</span></span></code></pre></div><h3 id="explanation" tabindex="-1">Explanation <a class="header-anchor" href="#explanation" aria-label="Permalink to &quot;Explanation&quot;">​</a></h3><ul><li><strong><code>main()</code>-function</strong>: Instantiates the <code>StarLocalDPModel</code> class automatically executing the analysis on the node (either as an aggregator or analyzer node). StarLocalDPModel extends the standard StarModel by incorporating Local Differential Privacy mechanisms to enhance privacy during federated analysis.</li></ul><p>This script serves as an example for performing privacy-preserving federated analysis using FHIR data with Local Differential Privacy.</p><h3 id="understanding-local-differential-privacy-in-starlocaldpmodel" tabindex="-1">Understanding Local Differential Privacy in <code>StarLocalDPModel</code> <a class="header-anchor" href="#understanding-local-differential-privacy-in-starlocaldpmodel" aria-label="Permalink to &quot;Understanding Local Differential Privacy in \`StarLocalDPModel\`&quot;">​</a></h3><div class="warning custom-block"><p class="custom-block-title">Info</p><p>In its current state, Local Differential Privacy is only supported for analyzes that return results with a single numeric value.</p></div><p><code>StarLocalDPModel</code> is an enhanced version of <code>StarModel</code> that implements Local Differential Privacy (LocalDP) to strengthen privacy guarantees during distributed analysis. The key difference is the addition of calibrated noise to the final aggregated results before they are sent to the Hub.</p><h4 id="key-parameters-for-differential-privacy" tabindex="-1">Key Parameters for Differential Privacy <a class="header-anchor" href="#key-parameters-for-differential-privacy" aria-label="Permalink to &quot;Key Parameters for Differential Privacy&quot;">​</a></h4><p>When using <code>StarLocalDPModel</code>, two additional parameters must be specified during instantiation:</p><div class="language-python vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">StarLocalDPModel(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    analyzer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MyAnalyzer,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    aggregator</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">MyAggregator,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    data_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;fhir&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    query</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;Patient?_summary=count&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    simple_analysis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">True</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    output_type</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;str&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    epsilon</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,                     </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Privacy budget for differential privacy</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    sensitivity</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1.0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,                 </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># Sensitivity parameter for differential privacy</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    analyzer_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    aggregator_kwargs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">None</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><h4 id="privacy-parameters-explained" tabindex="-1">Privacy Parameters Explained <a class="header-anchor" href="#privacy-parameters-explained" aria-label="Permalink to &quot;Privacy Parameters Explained&quot;">​</a></h4><ul><li><strong><code>epsilon</code></strong> (Privacy Budget): Controls the privacy-utility tradeoff. Lower values provide stronger privacy protection but add more noise to the results. Higher values provide more accurate results but weaker privacy guarantees. <ul><li>Typical values range from 0.1 (strong privacy) to 10.0 (weak privacy)</li><li>In this example: <code>epsilon=1.0</code> provides a moderate level of privacy</li></ul></li><li><strong><code>sensitivity</code></strong>: Represents the maximum amount that any single individual&#39;s data can change the analysis result. This is problem-specific and should be determined based on your analysis. <ul><li>For counting queries, sensitivity is typically 1.0 (one person can change the count by at most 1)</li><li>In this example: <code>sensitivity=1.0</code> is appropriate for patient counting</li></ul></li></ul><h4 id="output-with-differential-privacy-vs-without" tabindex="-1">Output with Differential Privacy vs Without <a class="header-anchor" href="#output-with-differential-privacy-vs-without" aria-label="Permalink to &quot;Output with Differential Privacy vs Without&quot;">​</a></h4><ul><li><strong>Without Differential Privacy</strong>: The final aggregated result is the exact sum of patient counts from all nodes. <ul><li>Example Output: <code>Total Patient Count: 118</code></li></ul></li><li><strong>With Differential Privacy</strong>: The final aggregated result includes added noise, making it an approximate count that protects individual privacy.\` <ul><li>Example Output: <code>Total Patient Count (with DP): 119.1</code></li></ul></li></ul><h4 id="how-noise-is-applied" tabindex="-1">How Noise is Applied <a class="header-anchor" href="#how-noise-is-applied" aria-label="Permalink to &quot;How Noise is Applied&quot;">​</a></h4><p>Executing an analysis with <code>StarLocalDPModel</code> will add Laplace noise to the final results sent by the aggregator node to the Hub. The scale of the noise is calculated as:</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>noise_scale = sensitivity / epsilon</span></span></code></pre></div><p>The Laplace distribution is then used to sample noise that is added to the aggregated result, ensuring differential privacy while maintaining statistical utility.</p><p>For more information, see the <a href="https://docs.opendp.org/en/stable/api/python/opendp.measurements.html#opendp.measurements.make_laplace" target="_blank" rel="noreferrer">OpenDP documentation on Laplace mechanism</a>.</p><h4 id="benefits-of-local-differential-privacy" tabindex="-1">Benefits of Local Differential Privacy <a class="header-anchor" href="#benefits-of-local-differential-privacy" aria-label="Permalink to &quot;Benefits of Local Differential Privacy&quot;">​</a></h4><ul><li><strong>Privacy Protection</strong>: Even if an adversary has access to the final aggregated results, they cannot determine whether any specific individual&#39;s data was included in the analysis.</li><li><strong>Quantifiable Privacy</strong>: The epsilon parameter provides a mathematically rigorous measure of privacy loss.</li><li><strong>Regulatory Compliance</strong>: Helps meet privacy requirements in healthcare and other sensitive domains.</li><li><strong>Trust</strong>: Participants can be assured that their individual data cannot be reverse-engineered from the published results.</li></ul><h4 id="considerations-when-using-differential-privacy" tabindex="-1">Considerations When Using Differential Privacy <a class="header-anchor" href="#considerations-when-using-differential-privacy" aria-label="Permalink to &quot;Considerations When Using Differential Privacy&quot;">​</a></h4><ul><li><strong>Accuracy vs. Privacy Tradeoff</strong>: Lower epsilon values provide stronger privacy but reduce result accuracy.</li><li><strong>Result Interpretation</strong>: The added noise means results are approximate. Consider running sensitivity analyses with different epsilon values.</li><li><strong>Single Numeric Results</strong>: Currently, the implementation only supports single numeric outputs. Complex multi-dimensional results are not yet supported.</li><li><strong>Sensitivity Calculation</strong>: Properly calculating sensitivity is crucial for meaningful privacy guarantees. Underestimating sensitivity can compromise privacy; overestimating it adds unnecessary noise.</li></ul>`,27)]))}const g=a(t,[["render",l]]);export{c as __pageData,g as default};
